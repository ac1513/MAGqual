configfile: "config/config.yaml"
cluster_json = "config/cluster.json"

JOBID = config["JOBID"]
ASM_LOC = config["ASM_LOC"]
BIN_LOC = config["BIN_LOC"]
checkmdb = config["checkm_db"]
baktadb = config["bakta_db"]

import json
import os,sys

cluster=dict()
if os.path.exists(cluster_json):
    with open(cluster_json) as file:
        cluster = json.load(file)

if BIN_LOC.endswith("/") == False :
    BIN_LOC = BIN_LOC + "/"

(CLUSTERS,) = glob_wildcards(BIN_LOC + "{CLUSTERS}.fasta")

rule all:
    input:
        expand("analysis/bakta/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", JOBID = JOBID, CLUSTERS = CLUSTERS, ext=[ "faa", "txt", "tsv"]),
        expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID),
        expand("analysis/genome_bins/{JOBID}_qual_MAGs.txt", JOBID = JOBID),
        expand("analysis/{JOBID}_mag_qual_statistics.csv", JOBID = JOBID)

rule bakta_db: 
    output: "databases/bakta/{JOBID}_baktadb.log"
    conda:
        "envs/bakta_env.yaml"
    params: 
        database = baktadb
    benchmark:
        "benchmarks/bakta/{JOBID}_baktadb.tsv"
    shell:
        """
        if [ ! -z {params.database} ] && [ -d {params.database} ]; then 
            cd databases/
            rm -r bakta/
            cd ..
            ln -sTf {params.database} databases/bakta
        else
            wget https://zenodo.org/record/7669534/files/db-light.tar.gz
            mkdir -p databases/bakta/
            tar -xzf db-light.tar.gz -C databases/bakta/ --strip-components 1
            rm db-light.tar.gz
            amrfinder_update --force_update --database databases/bakta/amrfinderplus-db/
        fi
        touch databases/bakta/{JOBID}_baktadb.log
        """

rule bakta:
    input:
        clusters = expand("{BIN_LOC}{{CLUSTERS}}.fasta", BIN_LOC=BIN_LOC),
        database = expand("databases/bakta/{JOBID}_baktadb.log", JOBID = JOBID)
    output:
        file = expand("analysis/bakta/{{JOBID}}/{{CLUSTERS}}/{{CLUSTERS}}.{ext}", ext=[ "faa", "txt", "tsv"])
    params:
        dir = "analysis/bakta/{JOBID}/{CLUSTERS}/",
        prefix = "{CLUSTERS}",
        database = "databases/bakta/"
    benchmark:
        "benchmarks/bakta/{JOBID}_{{CLUSTERS}}_bakta.tsv"
    conda:
        "envs/bakta_env.yaml"
    resources:
      threads=cluster["bakta"]["threads"],
      mem=cluster["__default__"]["mem"],
      time=cluster["__default__"]["time"]
    shell:
        """
        bakta --db={params.database} --output {params.dir} --prefix {params.prefix} --threads {resources.threads} {input.clusters}
        """


rule checkm_db: 
    output: "databases/checkm/{JOBID}_checkmdb.log"
    conda:
        "envs/checkm.yaml"
    params: 
        database = checkmdb
    benchmark:
        "benchmarks/checkm/{JOBID}_checkmdb.tsv"
    shell:
        """
        if [ ! -z {params.database} ] && [ -d {params.database} ]; then 
            cd databases
            rm -r checkm/
            cd ..
            ln -sTf {params.database} databases/checkm
        else
            wget https://zenodo.org/record/7401545/files/checkm_data_2015_01_16.tar.gz
            mkdir -p databases/checkm/
            tar -xzf checkm_data_2015_01_16.tar.gz -C databases/checkm/
            rm checkm_data_2015_01_16.tar.gz
        fi
        touch databases/checkm/{JOBID}_checkmdb.log
        """

rule checkm:
  input:
      clusters = expand("{BIN_LOC}{CLUSTERS}.fasta", BIN_LOC = BIN_LOC, CLUSTERS = CLUSTERS),
      #wait_for = expand("analysis/bakta/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", JOBID = JOBID, CLUSTERS = CLUSTERS, ext=["faa", "txt", "tsv"]),
      database_log = expand("databases/checkm/{JOBID}_checkmdb.log", JOBID = JOBID)
  output:
      log = "analysis/checkm/{JOBID}/{JOBID}_checkm.log",
  params:
      out = expand("analysis/checkm/{JOBID}", JOBID=JOBID),
      input_loc = BIN_LOC,
      refin = ASM_LOC,
      database = "databases/checkm/"
  benchmark:
      "benchmarks/checkm/{JOBID}_checkm.tsv"
  conda:
      "envs/checkm.yaml"
  resources:
      threads=cluster["checkm"]["threads"],
      time =cluster["checkm"]["time"],
      mem=cluster["__default__"]["mem"]
  shell:
      """
      checkmdb={params.database}
      echo ${{checkmdb}} | checkm data setRoot ${{checkmdb}}
      checkm lineage_wf -f {output.log} --force_overwrite --tab_table -x fasta -t {resources.threads} {params.input_loc} {params.out}
      """

rule seqkit:
    input:
        clusters = expand("{BIN_LOC}{CLUSTERS}.fasta", BIN_LOC = BIN_LOC, CLUSTERS = CLUSTERS),
        checkm = expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID)
    output:
        tsv = "analysis/{JOBID}_seqkit_stats.tsv"
    benchmark:
        "benchmarks/seqkit/{JOBID}_seqkit.tsv"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit stats -aT {input.clusters} > {output.tsv}
        """

rule high_mags:
    input:
        bakta = expand("analysis/bakta/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", ext=[ "faa", "txt", "tsv"], CLUSTERS = CLUSTERS, JOBID = JOBID),
        seqkit = expand("analysis/{JOBID}_seqkit_stats.tsv", JOBID=JOBID),
        checkm = expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID)
    output:
        txt = "analysis/genome_bins/{JOBID}_qual_MAGs.txt",
        stats = "analysis/{JOBID}_mag_qual_statistics.csv"
    params:
        bakta = expand("analysis/bakta/{JOBID}/", JOBID = JOBID),
        bin_loc = BIN_LOC,
        jobid = JOBID,
        out_loc = "analysis/genome_bins/"
    benchmark:
        "benchmarks/scripts/{JOBID}_python.tsv"
    conda :
        "envs/py3.yaml"
    resources:
        mem=cluster["__default__"]["mem"],
        threads=cluster["__default__"]["threads"],
        time=cluster["__default__"]["time"]
    shell:
        """
        python workflow/scripts/python/qual_parse.py {params.out_loc} {input.checkm} {params.bakta} {input.seqkit} {params.bin_loc} {params.jobid} > {output.txt}
        """
