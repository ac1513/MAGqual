configfile: "config/config.yaml"
cluster_json = "config/cluster.json"

JOBID = config["JOBID"]
REFIN = config["REFIN"]
BIN_LOC = config["BIN_LOC"]
checkmdb = config["checkm_db_root"]

import json
import os,sys

cluster=dict()
if os.path.exists(cluster_json):
    with open(cluster_json) as file:
        cluster = json.load(file)

if BIN_LOC.endswith("/") == False :
    BIN_LOC = BIN_LOC + "/"


(CLUSTERS,) = glob_wildcards(BIN_LOC + "{CLUSTERS}.fasta")
print("here are the" + str(CLUSTERS))
rule all:
    input:
        expand("analysis/bakta/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", JOBID = JOBID, CLUSTERS = CLUSTERS, ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"]),
        #expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID),
        #expand("analysis/genome_bins/{JOBID}_qual_MAGs.txt", JOBID = JOBID)

rule bakta:
    input:
        clusters = expand("{BIN_LOC}{{CLUSTERS}}.fasta", BIN_LOC=BIN_LOC)
    output:
        file = expand("analysis/bakta/{{JOBID}}/{{CLUSTERS}}/{{CLUSTERS}}.{ext}", ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"])
    params:
        dir = "analysis/bakta/{JOBID}/{CLUSTERS}/",
        prefix = "{CLUSTERS}"
    conda:
        "envs/bakta_env.yaml"
    resources:
      threads=cluster["bakta"]["threads"],
      mem=cluster["__default__"]["mem"],
      time=cluster["__default__"]["time"]
    shell:
        """
        #awk '/^>/{{print substr($1,1,21); next}}{{print}}' < {input.clusters} > {params.bakta}
        bakta {input.clusters} --outdir {params.dir} --prefix {params.prefix} --cpus {resources.threads}
        #rm {params.bakta}
        """

# rule checkm:
#   input:
#       expand("{BIN_LOC}{CLUSTERS}.fasta", BIN_LOC = BIN_LOC, CLUSTERS = CLUSTERS),
#       wait_for = expand("analysis/bakta/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", JOBID = JOBID, CLUSTERS = CLUSTERS, ext=["err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"])
#   output:
#       log = expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID),
#   params:
#       out = expand("analysis/checkm/{JOBID}", JOBID=JOBID),
#       input = BIN_LOC,
#       refin = REFIN,
#       checkmdb = checkmdb
#   conda:
#       "envs/checkm.yaml"
#   resources:
#     threads=cluster["checkm"]["threads"],
#     time =cluster["checkm"]["time"],
#     mem=cluster["__default__"]["mem"],
#   shell:
#       """
#       checkm_db={params.checkmdb}
#       echo ${{checkm_db}} | checkm data setRoot ${{checkm_db}}
#       checkm lineage_wf -f {output.log} --tab_table -x fasta -t {resources.threads} {params.input} {params.out}
#       """
#
# rule high_mags:
#     input:
#         bakta = expand("analysis/bakta/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"], CLUSTERS = CLUSTERS, JOBID = JOBID),
#         checkm = expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID)
#     output:
#         txt = "analysis/genome_bins/{JOBID}_qual_MAGs.txt"
#     params:
#         bakta = expand("analysis/bakta/{JOBID}/", JOBID = JOBID),
#         bin_loc = BIN_LOC,
#         jobid = JOBID,
#         out_loc = "analysis/genome_bins/"
#     conda :
#         "envs/py3.yaml"
#     resources:
#         mem=cluster["__default__"]["mem"],
#         threads=cluster["__default__"]["threads"],
#         time=cluster["__default__"]["time"]
#     shell:
#         """
#         python workflow/scripts/python/qual_parse.py {params.out_loc} {input.checkm} {params.bakta} {params.bin_loc} {params.jobid} > {output.txt}
#         """
